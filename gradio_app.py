"""
Gradio åº”ç”¨
æä¾› Web UI ç•Œé¢
"""
import gradio as gr
from config import settings
import requests
import os

# API åŸºç¡€ URL
API_BASE_URL = "http://localhost:8000"

# åˆå§‹åŒ– LangChain (éœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡)
llm = None
try:
    from langchain_openai import ChatOpenAI
    from langchain.chains import LLMChain
    from langchain.prompts import PromptTemplate
    
    if os.getenv("OPENAI_API_KEY"):
        llm = ChatOpenAI(temperature=0.7, model_name="gpt-3.5-turbo")
except ImportError:
    try:
        from langchain.llms import OpenAI
        if os.getenv("OPENAI_API_KEY"):
            llm = OpenAI(temperature=0.7)
    except ImportError:
        print("LangChain æœªå®‰è£…æˆ–ç‰ˆæœ¬ä¸å…¼å®¹")
except Exception as e:
    print(f"LangChain åˆå§‹åŒ–å¤±è´¥: {str(e)}")


def login(username: str, password: str):
    """ç™»å½•åŠŸèƒ½"""
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/auth/login",
            data={"username": username, "password": password}
        )
        if response.status_code == 200:
            token = response.json()["access_token"]
            return f"ç™»å½•æˆåŠŸï¼Token: {token[:20]}..."
        else:
            return f"ç™»å½•å¤±è´¥: {response.json().get('detail', 'æœªçŸ¥é”™è¯¯')}"
    except Exception as e:
        return f"ç™»å½•é”™è¯¯: {str(e)}"


def register(username: str, email: str, password: str):
    """æ³¨å†ŒåŠŸèƒ½"""
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/auth/register",
            json={
                "username": username,
                "email": email,
                "password": password
            }
        )
        if response.status_code == 201:
            return "æ³¨å†ŒæˆåŠŸï¼"
        else:
            return f"æ³¨å†Œå¤±è´¥: {response.json().get('detail', 'æœªçŸ¥é”™è¯¯')}"
    except Exception as e:
        return f"æ³¨å†Œé”™è¯¯: {str(e)}"


def query_vector_db(query_text: str, n_results: int = 5, token: str = ""):
    """æŸ¥è¯¢å‘é‡æ•°æ®åº“"""
    if not token:
        return "è¯·å…ˆç™»å½•è·å– Token"
    
    try:
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.post(
            f"{API_BASE_URL}/api/vector/query",
            json={
                "query_texts": [query_text],
                "n_results": n_results
            },
            headers=headers
        )
        if response.status_code == 200:
            results = response.json()["results"]
            return f"æŸ¥è¯¢ç»“æœ: {results}"
        else:
            return f"æŸ¥è¯¢å¤±è´¥: {response.json().get('detail', 'æœªçŸ¥é”™è¯¯')}"
    except Exception as e:
        return f"æŸ¥è¯¢é”™è¯¯: {str(e)}"


def search_es(index: str, query_text: str, token: str = ""):
    """æœç´¢ Elasticsearch"""
    if not token:
        return "è¯·å…ˆç™»å½•è·å– Token"
    
    try:
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.post(
            f"{API_BASE_URL}/api/es/search",
            json={
                "index": index,
                "query": {
                    "match": {
                        "_all": query_text
                    }
                }
            },
            headers=headers
        )
        if response.status_code == 200:
            results = response.json()["results"]
            return f"æœç´¢ç»“æœ: {results}"
        else:
            return f"æœç´¢å¤±è´¥: {response.json().get('detail', 'æœªçŸ¥é”™è¯¯')}"
    except Exception as e:
        return f"æœç´¢é”™è¯¯: {str(e)}"


def chat_with_llm(message: str, history: list):
    """ä¸ LLM å¯¹è¯"""
    if llm is None:
        return "LangChain æœªåˆå§‹åŒ–ï¼Œè¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡"
    
    try:
        from langchain.chains import LLMChain
        from langchain.prompts import PromptTemplate
        
        prompt = PromptTemplate(
            input_variables=["question"],
            template="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿é™©é¡¾é—®ã€‚è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{question}"
        )
        chain = LLMChain(llm=llm, prompt=prompt)
        response = chain.run(message)
        return response
    except Exception as e:
        return f"LLM é”™è¯¯: {str(e)}"


# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="InsurGuide - æ™ºèƒ½ä¿é™©æŒ‡å—ç³»ç»Ÿ") as demo:
    gr.Markdown("# ğŸ›¡ï¸ InsurGuide - æ™ºèƒ½ä¿é™©æŒ‡å—ç³»ç»Ÿ")
    gr.Markdown("åŸºäº FastAPIã€LangChain å’Œ Gradio æ„å»ºçš„æ™ºèƒ½ä¿é™©æŒ‡å—å¹³å°")
    
    with gr.Tabs():
        # è®¤è¯æ ‡ç­¾é¡µ
        with gr.Tab("ğŸ” ç”¨æˆ·è®¤è¯"):
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ç™»å½•")
                    login_username = gr.Textbox(label="ç”¨æˆ·å", placeholder="è¯·è¾“å…¥ç”¨æˆ·å")
                    login_password = gr.Textbox(label="å¯†ç ", type="password", placeholder="è¯·è¾“å…¥å¯†ç ")
                    login_btn = gr.Button("ç™»å½•", variant="primary")
                    login_output = gr.Textbox(label="ç™»å½•ç»“æœ", lines=3)
                    
                    login_btn.click(
                        fn=login,
                        inputs=[login_username, login_password],
                        outputs=login_output
                    )
                
                with gr.Column():
                    gr.Markdown("### æ³¨å†Œ")
                    reg_username = gr.Textbox(label="ç”¨æˆ·å", placeholder="è¯·è¾“å…¥ç”¨æˆ·å")
                    reg_email = gr.Textbox(label="é‚®ç®±", placeholder="è¯·è¾“å…¥é‚®ç®±")
                    reg_password = gr.Textbox(label="å¯†ç ", type="password", placeholder="è¯·è¾“å…¥å¯†ç ")
                    reg_btn = gr.Button("æ³¨å†Œ", variant="primary")
                    reg_output = gr.Textbox(label="æ³¨å†Œç»“æœ", lines=3)
                    
                    reg_btn.click(
                        fn=register,
                        inputs=[reg_username, reg_email, reg_password],
                        outputs=reg_output
                    )
        
        # å‘é‡æ•°æ®åº“æ ‡ç­¾é¡µ
        with gr.Tab("ğŸ” å‘é‡æ•°æ®åº“"):
            gr.Markdown("### æŸ¥è¯¢å‘é‡æ•°æ®åº“")
            vector_token = gr.Textbox(label="Token", placeholder="è¯·è¾“å…¥ç™»å½•åè·å–çš„ Token")
            vector_query = gr.Textbox(label="æŸ¥è¯¢æ–‡æœ¬", placeholder="è¯·è¾“å…¥è¦æŸ¥è¯¢çš„å†…å®¹")
            vector_n_results = gr.Slider(minimum=1, maximum=20, value=5, label="è¿”å›ç»“æœæ•°é‡")
            vector_btn = gr.Button("æŸ¥è¯¢", variant="primary")
            vector_output = gr.Textbox(label="æŸ¥è¯¢ç»“æœ", lines=10)
            
            vector_btn.click(
                fn=query_vector_db,
                inputs=[vector_query, vector_n_results, vector_token],
                outputs=vector_output
            )
        
        # Elasticsearch æ ‡ç­¾é¡µ
        with gr.Tab("ğŸ“Š Elasticsearch"):
            gr.Markdown("### æœç´¢ Elasticsearch")
            es_token = gr.Textbox(label="Token", placeholder="è¯·è¾“å…¥ç™»å½•åè·å–çš„ Token")
            es_index = gr.Textbox(label="ç´¢å¼•åç§°", placeholder="è¯·è¾“å…¥ç´¢å¼•åç§°", value="insurguide")
            es_query = gr.Textbox(label="æœç´¢æ–‡æœ¬", placeholder="è¯·è¾“å…¥è¦æœç´¢çš„å†…å®¹")
            es_btn = gr.Button("æœç´¢", variant="primary")
            es_output = gr.Textbox(label="æœç´¢ç»“æœ", lines=10)
            
            es_btn.click(
                fn=search_es,
                inputs=[es_index, es_query, es_token],
                outputs=es_output
            )
        
        # LLM å¯¹è¯æ ‡ç­¾é¡µ
        with gr.Tab("ğŸ’¬ AI å¯¹è¯"):
            gr.Markdown("### ä¸ AI ä¿é™©é¡¾é—®å¯¹è¯")
            chatbot = gr.Chatbot(label="å¯¹è¯å†å²")
            msg = gr.Textbox(label="è¾“å…¥æ¶ˆæ¯", placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")
            clear = gr.Button("æ¸…ç©ºå¯¹è¯")
            
            def respond(message, chat_history):
                bot_message = chat_with_llm(message, chat_history)
                chat_history.append((message, bot_message))
                return "", chat_history
            
            msg.submit(respond, [msg, chatbot], [msg, chatbot])
            clear.click(lambda: None, None, chatbot, queue=False)


if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=settings.GRADIO_PORT,
        share=settings.GRADIO_SHARE
    )
